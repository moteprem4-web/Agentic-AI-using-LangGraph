{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict,Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from pydantic import BaseModel,Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff536408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Moon orbits the Earth at an average distance of about **384,400 kilometers (≈238,900 miles)**.  \n",
      "\n",
      "Because its orbit is elliptical, the actual distance varies:\n",
      "\n",
      "- **Perigee** (closest approach): roughly **363,300 km** (≈225,600 mi)  \n",
      "- **Apogee** (farthest point): roughly **405,500 km** (≈252,000 mi)\n",
      "\n",
      "So, while the average separation is ~384 thousand kilometers, the Moon can be a bit nearer or farther depending on where it is in its orbit.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# 1. Set your NEW API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = 'AIzaSyANyksWpr2ptAdCmQz4XXXXXXXXXXXXXX'\n",
    "\n",
    "# 2. Use the correct model string for the current API\n",
    "# Note: Using \"gemini-1.5-flash\" is the best path for LangGraph\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-pro\", \n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 3. Test it before running the workflow\n",
    "try:\n",
    "    response = model.invoke(\"How far is the moon from the earth?\")\n",
    "    print(response.content)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "94528193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class SentimentSchema(TypedDict):\n",
    "    sentiment: Literal[\"positive\", \"negative\"]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ac0dee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewState(TypedDict):\n",
    "\n",
    "    review: str\n",
    "    sentiment: Literal[\"positive\", \"negative\"]\n",
    "    diagnosis: dict\n",
    "    response: str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "0a2bb503",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentSchema(BaseModel):\n",
    "\n",
    "    sentiment: Literal[\"positive\", \"negative\"] = Field(description='Sentiment of the review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6034d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisSchema(BaseModel):\n",
    "    issue_type: Literal[\"UX\", \"Performance\", \"Bug\", \"Support\", \"Other\"] = Field(description='The category of issue mentioned in the review')\n",
    "    tone: Literal[\"angry\", \"frustrated\", \"disappointed\", \"calm\"] = Field(description='The emotional tone expressed by the user')\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\"] = Field(description='How urgent or critical the issue appears to be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952b2de",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'with_structured_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[201]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m structured_model = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_structured_output\u001b[49m(SentimentSchema)\n\u001b[32m      2\u001b[39m structured_model2 = model.with_structured_output(DiagnosisSchema)\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'with_structured_output'"
     ]
    }
   ],
   "source": [
    "structured_model = model.with_structured_output(SentimentSchema)\n",
    "structured_model2=model.with_structured_output(DiagnosisSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1008ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state: ReviewState):\n",
    "\n",
    "    prompt = f'For the following review find out the sentiment \\n {state[\"review\"]}'\n",
    "    sentiment = structured_model.invoke(prompt).sentiment\n",
    "\n",
    "    return {'sentiment': sentiment}\n",
    "\n",
    "def check_sentiment(state: ReviewState) -> Literal[\"positive_response\", \"run_diagnosis\"]:\n",
    "\n",
    "    if state['sentiment'] == 'positive':\n",
    "        return 'positive_response'\n",
    "    else:\n",
    "        return 'run_diagnosis'\n",
    "    \n",
    "def positive_response(state: ReviewState):\n",
    "\n",
    "    prompt = f\"\"\"Write a  warm thank-you only one  message in response to this review:\n",
    "    \\n\\n\\\"{state['review']}\\\"\\n\n",
    "Also, kindly ask the user to leave feedback on our website.\"\"\"\n",
    "    \n",
    "    response = model.invoke(prompt).content\n",
    "\n",
    "    return {'response': response}\n",
    "\n",
    "def run_diagnosis(state: ReviewState):\n",
    "\n",
    "    prompt = f\"\"\"Diagnose this negative review:\\n\\n{state['review']}\\n\"\n",
    "    \"Return issue_type, tone, and urgency.\n",
    "\"\"\"\n",
    "    response = structured_model2.invoke(prompt)\n",
    "\n",
    "    return {'diagnosis': response.model_dump()}\n",
    "\n",
    "def negative_response(state: ReviewState):\n",
    "\n",
    "    diagnosis = state['diagnosis']\n",
    "\n",
    "    prompt = f\"\"\"You are a support assistant.\n",
    "The user had a '{diagnosis['issue_type']}' issue, sounded '{diagnosis['tone']}', and marked urgency as '{diagnosis['urgency']}'.\n",
    "Write an empathetic, helpful resolution message.\n",
    "\"\"\"\n",
    "    response = model.invoke(prompt).content\n",
    "\n",
    "    return {'response': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ReviewState)\n",
    "\n",
    "graph.add_node('find_sentiment', find_sentiment)\n",
    "graph.add_node('positive_response', positive_response)\n",
    "graph.add_node('run_diagnosis', run_diagnosis)\n",
    "graph.add_node('negative_response', negative_response)\n",
    "\n",
    "graph.add_edge(START, 'find_sentiment')\n",
    "\n",
    "graph.add_conditional_edges('find_sentiment', check_sentiment)\n",
    "\n",
    "graph.add_edge('positive_response', END)\n",
    "\n",
    "graph.add_edge('run_diagnosis', 'negative_response')\n",
    "graph.add_edge('negative_response', END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ee400c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000024DADF456A0>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a806e05",
   "metadata": {},
   "outputs": [
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Error calling model 'gemini-2.5-pro' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\\nPlease retry in 27.991371313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerDay-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3047\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3046\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3049\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3050\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\google\\genai\\models.py:5227\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5226\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5227\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5228\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5229\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5231\u001b[39m function_map = _extra_utils.get_function_map(parsed_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\google\\genai\\models.py:4009\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   4007\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m4009\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4010\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   4011\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4013\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   4014\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4015\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\google\\genai\\_api_client.py:1386\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1383\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1384\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1385\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1387\u001b[39m response_body = (\n\u001b[32m   1388\u001b[39m     response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1389\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\google\\genai\\_api_client.py:1220\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1219\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1220\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\google\\genai\\_api_client.py:1199\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1192\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1193\u001b[39m     method=http_request.method,\n\u001b[32m   1194\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1197\u001b[39m     timeout=http_request.timeout,\n\u001b[32m   1198\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1199\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1201\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1202\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\google\\genai\\errors.py:121\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    119\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\google\\genai\\errors.py:146\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\\nPlease retry in 27.991371313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerDay-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[184]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m initial_state = {\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mreview\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mui is very good\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3071\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3068\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3069\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3071\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3085\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[181]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mfind_sentiment\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_sentiment\u001b[39m(state: ReviewState):\n\u001b[32m      3\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFor the following review find out the sentiment \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[33m\"\u001b[39m\u001b[33mreview\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     sentiment = \u001b[43mstructured_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m.sentiment\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m: sentiment}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3149\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3147\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3148\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3149\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3150\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3151\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5557\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5550\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5552\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5555\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5556\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5558\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5559\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5560\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5561\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2535\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2532\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2533\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2535\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:402\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1121\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m     **kwargs: Any,\n\u001b[32m   1119\u001b[39m ) -> LLMResult:\n\u001b[32m   1120\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:931\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    930\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m         )\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    939\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1233\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1231\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1237\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3051\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3047\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28mself\u001b[39m.client.models.generate_content(\n\u001b[32m   3048\u001b[39m         **request,\n\u001b[32m   3049\u001b[39m     )\n\u001b[32m   3050\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m3051\u001b[39m     \u001b[43m_handle_client_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3053\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Prem\\Desktop\\LangGraph\\myvenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:145\u001b[39m, in \u001b[36m_handle_client_error\u001b[39m\u001b[34m(e, request)\u001b[39m\n\u001b[32m    143\u001b[39m model_name = request.get(\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    144\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calling model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m: Error calling model 'gemini-2.5-pro' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\\nPlease retry in 27.991371313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerDay-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}",
      "During task with name 'find_sentiment' and id '7d576ee7-a686-a19d-bc4f-61f11f914611'"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    'review': \"ui is very good\"}\n",
    "\n",
    "workflow.invoke(initial_state)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
